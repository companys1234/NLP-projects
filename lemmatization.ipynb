{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7EQnwwNMXIH",
        "outputId": "58bf0fb7-91a7-4368-aab2-9769b82e4d2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "text = \"The cats were running faster than the dogs.\"\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "print(f\"Original Text: {text}\")\n",
        "print(f\"Lemmatized Words: {lemmatized_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT6t0PP_RZge",
        "outputId": "1326c6bd-5302-44f6-a2a1-85cf0c83cebe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: The cats were running faster than the dogs.\n",
            "Lemmatized Words: ['The', 'cat', 'were', 'running', 'faster', 'than', 'the', 'dog', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "sentence = \"The children are running towards a better place.\"\n",
        "\n",
        "tokens = word_tokenize(sentence)\n",
        "\n",
        "tagged_tokens = pos_tag(tokens)\n",
        "\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return 'a'\n",
        "    elif tag.startswith('V'):\n",
        "        return 'v'\n",
        "    elif tag.startswith('N'):\n",
        "        return 'n'\n",
        "    elif tag.startswith('R'):\n",
        "        return 'r'\n",
        "    else:\n",
        "        return 'n'\n",
        "\n",
        "lemmatized_sentence = []\n",
        "\n",
        "for word, tag in tagged_tokens:\n",
        "    if word.lower() == 'are' or word.lower() in ['is', 'am']:\n",
        "        lemmatized_sentence.append(word)\n",
        "    else:\n",
        "        lemmatized_sentence.append(lemmatizer.lemmatize(word, get_wordnet_pos(tag)))\n",
        "\n",
        "print(\"Original Sentence: \", sentence)\n",
        "print(\"Lemmatized Sentence: \", ' '.join(lemmatized_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqEQBu1SRhGv",
        "outputId": "a6e2b563-e54c-477f-8aa7-8021767234b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence:  The children are running towards a better place.\n",
            "Lemmatized Sentence:  The child are run towards a good place .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kTgOyHLQR5GV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}